{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMt4BWYFWclIDrSdI/Yh8lQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RenanNB360/Modelo-Transformer-Sem-Uso-de-Frameworks/blob/main/Implementa%C3%A7%C3%A3o_Mecanismo_de_Aten%C3%A7%C3%A3o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalações"
      ],
      "metadata": {
        "id": "i2GWRfCitfLX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAASsf1FtCIN",
        "outputId": "dc47bc12-348b-4648-9ea4-80827328e454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext watermark\n",
        "%watermark -a \"Attention\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga0P0gkitpb5",
        "outputId": "c8bfe5be-6970-406f-e3ca-7ce4413d05d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Attention\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%watermark -v -m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1m68e46uSuK",
        "outputId": "611a0f64-229b-4f78-9cb5-c033de6279dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "Compiler    : GCC 11.4.0\n",
            "OS          : Linux\n",
            "Release     : 5.15.120+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anatomia da Arquitetura Transformer (Com Uso do framework PyTorch)"
      ],
      "metadata": {
        "id": "SauJnodxuAAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAla6Eqet7zq",
        "outputId": "bc9c39f4-0371-43aa-ff37-94bdc504065a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, n_heads, n_layers, dropout):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.n_heads = n_heads\n",
        "    self.n_layers = n_layers\n",
        "    self.dropout = dropout\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    self.attention = nn.MultiheadAttention(embedding_dim, n_heads, dropout = dropout)\n",
        "\n",
        "    self.feed_forward = nn.Sequential(\n",
        "        nn.Linear(embedding_dim, embedding_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(embedding_dim, embedding_dim)\n",
        "    )\n",
        "\n",
        "    self.out = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)\n",
        "    x = self.attention(x)\n",
        "    x = self.feed_forward(x)\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "JCOicHsXwS7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Transformer(vocab_size = 1000,\n",
        "                     embedding_dim = 32,\n",
        "                     n_heads = 4,\n",
        "                     n_layers = 2,\n",
        "                     dropout = 0.5)"
      ],
      "metadata": {
        "id": "N8bsk531yh2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.modules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwYAHlcJznzU",
        "outputId": "07db2e81-d2b9-47fb-8e7e-49640f9899ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.modules of Transformer(\n",
              "  (embedding): Embedding(1000, 32)\n",
              "  (attention): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "  )\n",
              "  (feed_forward): Sequential(\n",
              "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
              "  )\n",
              "  (out): Linear(in_features=32, out_features=1000, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Dx7FI3hz1bl",
        "outputId": "8c17f48e-712f-4ecf-8f0d-58c118d4a96a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiheadAttention(\n",
              "  (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construindo um modelo Transformer (Sem uso de Framework)"
      ],
      "metadata": {
        "id": "dY8u_C1xnsdz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O objetivo é que ele seja capaz de prever sequências de comprimeto igual a 10 tokens."
      ],
      "metadata": {
        "id": "d2S6bjg1n8ff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um modelo transformer consiste em várias partes:"
      ],
      "metadata": {
        "id": "4yPZq7MlpLfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Camada Embedding: Transforma as palavras em valores númericos de tamanho fixo.\n",
        "2.   Mecanismo de Atenção: Permite que o modelo foque em diferentes partes da entrada.\n",
        "3.   Camadas Encoder e Decoder: Processam os dados sequencialmente.\n",
        "4.   Camada linear e Softmax: Para as predições finais.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w6Q0ZfoloOhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este teste o objetivo é implementar o item 2, mas paraa deixar funcional vou implementar também os itens 1 e 4."
      ],
      "metadata": {
        "id": "-L-bRGTwpNIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hiperparâmetros Iniciais**"
      ],
      "metadata": {
        "id": "dsIGPcakpbLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "RxpKIRnhz-tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensão modelo\n",
        "dim_model = 64"
      ],
      "metadata": {
        "id": "upXbj4VLpoNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprimento da sequência\n",
        "seq_length = 10"
      ],
      "metadata": {
        "id": "cU_4yx_Ipvzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamanho do vocabulário\n",
        "vocab_size = 100"
      ],
      "metadata": {
        "id": "z8ZsiLpvp5id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Camada Embedding**"
      ],
      "metadata": {
        "id": "HhpNRxoyqKY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embedding(input, vocab_size, dim_model):\n",
        "  embed = np.random.randn(vocab_size, dim_model)\n",
        "  return np.array([embed[i] for i in input])"
      ],
      "metadata": {
        "id": "_5CX88pfp_13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Função de Ativação Softmax**"
      ],
      "metadata": {
        "id": "Pr5qtz2wyAJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  e_x = np.exp(x - np.max(x))\n",
        "  return e_x / e_x.sum(axis=-1).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "OLUo82rHq1lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scale Dot Product**"
      ],
      "metadata": {
        "id": "PkO0Qdfb05vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(Q, K, V):\n",
        "  matmul_qk = np.dot(Q, K.T)\n",
        "  depth = K.shape[-1]\n",
        "  logits = matmul_qk / np.sqrt(depth)\n",
        "  attention_weights = softmax(logits)\n",
        "  output = np.dot(attention_weights, V)\n",
        "  return output"
      ],
      "metadata": {
        "id": "_1qwCw7UyW2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saída do Modelo com Operação Linear e Softmax**"
      ],
      "metadata": {
        "id": "oPY2aOZ63R2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_and_softmax(input):\n",
        "  weights = np.random.randn(dim_model, vocab_size)\n",
        "  logits = np.dot(input, weights)\n",
        "  return softmax(logits)"
      ],
      "metadata": {
        "id": "PxCdB84r1sQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Construindo o Modelo Final**"
      ],
      "metadata": {
        "id": "vKXPFcSi5TB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_model(input):\n",
        "  embedded_input = embedding(input, vocab_size, dim_model)\n",
        "  attention_output = scaled_dot_product_attention(embedded_input, embedded_input, embedded_input)\n",
        "  output_probabilities = linear_and_softmax(attention_output)\n",
        "  output_indices = np.argmax(output_probabilities, axis = 1)\n",
        "  return output_indices"
      ],
      "metadata": {
        "id": "VcE6AVvP3xq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Usando o Modelo para Previsões**"
      ],
      "metadata": {
        "id": "PMw2Gxr_7ld8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = np.random.randint(0, vocab_size, seq_length)"
      ],
      "metadata": {
        "id": "Dh_UNSVo6D8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sequência de Entradas: {input_sequence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kYm2UNZ7z25",
        "outputId": "f7e554c3-9ffa-48a8-b065-351306c3b2eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequência de Entradas: [22 30 91 79  7 67  6 20 93 40]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = transformer_model(input_sequence)"
      ],
      "metadata": {
        "id": "9wBYu5lB78xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Saída do Modelo: {output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0A2EuR58D1g",
        "outputId": "742a1aca-2f01-4cd2-99f1-6884f49f3cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saída do Modelo: [87 40 34 71 99 34 93 83 91 42]\n"
          ]
        }
      ]
    }
  ]
}